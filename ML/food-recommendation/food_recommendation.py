# -*- coding: utf-8 -*-
"""food-recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M0RS3WCGCUMvkKu_qc2zozqLjc8Fs49N
"""

# Import Library
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, mean_absolute_error
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
# from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError
from tensorflow.keras.layers import Dense, LSTM, Input, Concatenate, BatchNormalization
from tensorflow.keras.layers import Dropout, LeakyReLU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import EarlyStopping
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import RandomizedSearchCV
from google.colab import drive
import json
import shutil

"""# **Data Loading**"""

# Memuat data
from google.colab import files
files.upload()

# Memuat data
from google.colab import files
files.upload()

# Load Data
child_data = pd.read_csv('/content/data_balita.csv')
food_data = pd.read_csv('/content/data_menu_mpasi.csv')

"""# **Data Understanding**

**data_balita.csv**
"""

# Menampilkan dataset balita teratas
child_data.head()

# Menampilkan jumlah row dan column (ukuran shape) dataset balita
child_data.shape

# Menampilkan informasi mengenai dataset balita
child_data.info()

# Memeriksa missing value pada dataset balita
child_data.isnull().sum()

# Memeriksa data duplikat pada dataset balita
child_duplicate = child_data.duplicated().sum()
print(f"Jumlah baris duplikat: {child_duplicate}")

# Menampilkan statistik deskriptif dari dataset balita untuk kolom numerik
child_data.describe()

"""# **data_menu_mpasi.csv**

Kode Umur meliputi:
- B1 => 6-8 bulan
- B2 => 9-11 bulan
- B3 => 12-24 bulan
- B4 => 25-60 bulan

Kode Frekuensi meliputi:
- F1 => 2 kali makanan utama
- F2 => 3 kali makanan utama
- F3 => 3 kali makanan utama & 1 kali makanan snack
- F4 => 3 kali makanan utama & 2 kali makanan snack
"""

# Menampilkan dataset food nutrition teratas
food_data.head()

"""Terlihat bahwa data tersusun secara terstruktur sehingga perlu dilakukan shuffle (pengacakan) pada row data untuk menghindari bias urutan saat training (model bisa jadi overfitting pada pola urutan, bukan pada fitur sebenarnya). Dan juga agar distribusi label lebih merata per batch sehingga bisa membantu konvergensi yang lebih stabil dan cepat dalam training."""

# Acak baris (shuffle)
food_shuffled = food_data.sample(frac=1, random_state=42).reset_index(drop=True)

# Simpan kembali
# df_shuffled.to_csv("menu_mpasi_shuffled.csv", index=False)

food_shuffled.head()

"""Terlihat bahwa hasil outputnya menunjukkan data sudah teracak."""

# Menampilkan jumlah row dan column (ukuran shape) dataset food nutrition
food_shuffled.shape

# Menampilkan informasi mengenai dataset food nutrition
food_shuffled.info()

# Memeriksa missing value pada dataset food nutrition
food_shuffled.isnull().sum()

# Memeriksa data duplikat pada dataset food nutrition
food_duplicate = food_shuffled.duplicated().sum()
print(f"Jumlah baris duplikat: {food_duplicate}")

# Menampilkan statistik deskriptif dari dataset food nutrition untuk kolom numerik
food_shuffled.describe()

"""# **Exploratory Data Analysis (EDA)**

**data_balita.csv**
"""

# Melakukan Mapping pada kolom kategorikal untuk memudahkan dalam melihat korelasi antar fitur
child_data['Label_kelamin'] = child_data['Jenis Kelamin'].map({'laki-laki': 0, 'perempuan': 1})
child_data['Label_Gizi'] = child_data['Status Gizi'].map({'severely stunted': 0, 'stunted': 1, 'normal': 2, 'tinggi': 3})
child_data

# Distribusi Jenis Kelamin pada dataset balita
jenis_kelamin = child_data['Jenis Kelamin'].value_counts()

plt.figure(figsize=(6, 4))
ax = sns.barplot(x=jenis_kelamin.index, y=jenis_kelamin.values, palette="pastel")

for i, value in enumerate(jenis_kelamin.values):
    ax.text(i, value + 0.05, str(value), ha='center', va='bottom', fontsize=12)

plt.title('Distribusi Jenis Kelamin')
plt.xlabel('Jenis Kelamin')
plt.ylabel('Jumlah')
plt.tight_layout()
plt.show()

# Distribusi Tinggi Badan Balita
plt.figure(figsize=(8, 5))
sns.histplot(child_data['Tinggi Badan (cm)'], kde=True, bins=10, color='skyblue')
plt.title('Distribusi Tinggi Badan')
plt.xlabel('Tinggi Badan (cm)')
plt.ylabel('Frekuensi')
plt.tight_layout()
plt.show()

# Distribusi Umur Balita
plt.figure(figsize=(8, 5))
sns.histplot(child_data['Umur (bulan)'], kde=True, bins=30, color='skyblue')
plt.title('Distribusi Umur (Bulan)')
plt.xlabel('Umur (Bulan)')
plt.ylabel('Frekuensi')
plt.tight_layout()
plt.show()

# Distribusi status gizi balita
plt.figure(figsize=(7, 5))
sns.countplot(x='Status Gizi', data = child_data, palette='Set2')
plt.title('Distribusi Status Gizi')
plt.xlabel('Status Gizi')
plt.ylabel('Jumlah')
plt.tight_layout()
plt.show()

# Hubungan antar fitur menggunakan table correlation matrix
numerical_features = child_data.select_dtypes(include=np.number)

correlation_matrix = numerical_features.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar_kws={'shrink': 0.8}, annot_kws={'size': 10})
plt.title('Correlation Matrix', fontsize=16)
plt.show()

"""Terlihat bahwa label kelamin menunjukkan korelasi yang sangat lemah dengan fitur lainnya sehingga dapat dilakukan dropping untuk tahap selanjutnya. Begitu pula dengan kolom 'Jenis Kelamin' yang secara langsung juga mencerminkan isi dari kolom 'Label_Kelamin'.

**data_menu_mpasi.csv**
"""

# Pilih hanya kolom nutrisi makanan dimana terlihat bertipe numerik
nutrition_columns = food_shuffled.select_dtypes(include=['float', 'int'])

# Hitung jumlah data non-null per kolom
count_data = nutrition_columns.count().reset_index()
count_data.columns = ['Kolom', 'Jumlah Data']

# 3. Buat Bar Plot
plt.figure(figsize=(16, 8))
sns.barplot(
    x='Kolom',
    y='Jumlah Data',
    data=count_data,
    palette='viridis',  # Warna
    edgecolor='black'
)

# 4. Tambahkan Judul dan Label
plt.title('Jumlah Data pada Setiap Kolom Kandungan Nutrisi Makanan', fontsize=14, pad=20)
plt.xlabel('Nama Kolom')
plt.ylabel('Jumlah Data')
plt.xticks(rotation=45, ha='right')  # Rotasi label kolom agar tidak tumpang tindih

# 5. Tambahkan nilai di atas setiap bar
for index, value in enumerate(count_data['Jumlah Data']):
    plt.text(index, value, str(value), ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Memilih hanya kolom dengan tipe data float (kolom nutrisi)
float_data = food_shuffled.select_dtypes(include=['int','float'])

# Korelasi antar fitur dengan tipe data float
corr_matrix = float_data.corr()

# Visualisasi korelasi
plt.figure(figsize=(24, 12))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', cbar=True)
plt.title('Korelasi Antar Fitur Nutrisi (Float Only)')
plt.show()

"""Terlihat bahwa semua fitur ingredients makanan menunjukkan mayoritas antar fitur memiliki korelasi yang kuat ditunjukkan dengan tanda warna merah pada tabel.

# **Data Preprocessing**

**data_balita.csv**
"""

# Drop kolom yang tidak diperlukan pada dataset balita
child_data.drop(['Jenis Kelamin'], inplace=True, axis=1)
child_data.drop(['Label_kelamin'], inplace=True, axis=1)
child_data

# Drop data duplikat
child_duplicate = child_data.drop_duplicates()
print(f' Data duplikat: {child_duplicate.duplicated().sum()}')
child_duplicate.info()

"""Terlihat data duplikat berhasil ditangani, dilakukan dropping karena jumlah dataset tergolong besar sehingga meskipun dilakukan dropping tidak akan terlalu berpengaruh untuk analisa lebih lanjut. Dan terlihat setelah dilakukan dropping, jumlah data tetap terhitung besar."""

# Memeriksa kembali data duplikat pada dataset balita
child_df = child_duplicate.duplicated().sum()
print(f"Jumlah baris duplikat: {child_df}")

# Mengembalikan dataframe dari child_duplicate menjadi child_data
child_data = child_duplicate

# Melakukan normalisasi data pada dataset balita
# Fitur yang Digunakan
child_features = ['Umur (bulan)', 'Tinggi Badan (cm)']

scaler_child = MinMaxScaler()
normalize_child_feature = scaler_child.fit_transform(child_data[child_features])

child_data.info()

# Mapping kolom 'Umur (bulan) menjadi kolom 'kode umur'
def map_kode_umur(umur):
  if 0 <= umur <= 5:
    return 'B0'
  elif 6 <= umur <= 8:
    return 'B1'
  elif 9 <= umur <= 11:
    return 'B2'
  elif 12 <= umur <= 24:
    return 'B3'
  elif 25 <= umur <= 60:
    return 'B4'
  return None

child_data['Kode Umur'] = child_data['Umur (bulan)'].apply(map_kode_umur)

child_data.head()

"""Terlihat setelah dilakukan SMOTE (The Synthetic Minority Over-Sampling Technique), data pada tiap kelasnya menjadi seimbang.

**data_menu_mpasi.csv**
"""

food_shuffled.head()

# Normalisasi fitur yang menunjukkan nutrisi makanan/ingredienst menggunakan MinMaxScaler
nutrient_cols = ['calories_kcal', 'fats_g', 'sod_mg', 'carb_g', 'fiber_g', 'sugar_g',
                 'protein_g', 'vitA_g', 'calcium_mg', 'thiamin_mg', 'zinc_mg',
                 'potassium_mg', 'magnesium_mg', 'vitE_mg', 'vitK_mcg', 'vitC_mg',
                 'vitB6_mg', 'copper_mg', 'carotene_mg', 'carotene_mcg',
                 'cryptoxanthin_mcg', 'lycopene_mcg', 'cholesterol_mg']

scaler = MinMaxScaler()
food_shuffled[nutrient_cols] = scaler.fit_transform(food_shuffled[nutrient_cols])

# filter sebelum merge agar menghindari join many to many
filtered_menu = food_shuffled[food_shuffled['Kode Umur'].isin(child_data['Kode Umur'].unique())]

# Merging data untuk menggabungkan data balita dan data menu mpasi
merged_df = pd.merge(child_data, filtered_menu, on='Kode Umur', how='inner')
merged_df

"""Untuk mengontrol jumlah data hasil merged sebelumnya, lakukan kombinasi data untuk mengontrol jumlah data dimana akan dengan menggabungkan setiap Balita dengan N Menu yang Sesuai Umur (Sampling Menu per Anak)"""

# Buat list hasil akhir
samples = []

for _, child in child_data.iterrows():
    umur_kode = child['Kode Umur']
    cocok_menu = filtered_menu[filtered_menu['Kode Umur'] == umur_kode]

    # Cek jika cocok_menu tidak kosong sebelum melakukan sampling
    if not cocok_menu.empty:
        # Ambil 3 menu secara acak
        sampled_menu = cocok_menu.sample(n=min(3, len(cocok_menu)), replace=True, random_state=42)

        # Tambahkan data anak ke menu yang dipilih
        for _, menu in sampled_menu.iterrows():
            combined = {**child.to_dict(), **menu.to_dict()}
            samples.append(combined)
    else:
        print(f"Skipping child with Kode Umur {umur_kode} as no matching menus were found in filtered_menu.")

# Ubah jadi DataFrame akhir
merged = pd.DataFrame(samples)

merged

# Tambahkan kolom 'child_id' dengan nilai unik berdasarkan jumlah baris
merged["child_id"] = range(1, len(merged) + 1)

# Pindahkan kolom 'child_id' ke posisi paling kiri
cols = ["child_id"] + [col for col in merged.columns if col != "child_id"]
merged = merged[cols]

# Periksa hasil
merged

from sklearn.preprocessing import LabelEncoder

merged["child_id"] = merged.index

le_menu = LabelEncoder()
merged["menu_id"] = le_menu.fit_transform(merged["Kode Menu"])

merged

"""# **Pipeline Collaborative Filtering**"""

def rekomendasi_menu(model, umur_bulan, label_gizi, data_menu):
    # Jika umur ≤ 6 bulan, override sistem
    if umur_bulan <= 6:
        return ["ASI Eksklusif / Susu Formula"]

    # Lanjutkan ke prediksi model untuk umur > 6 bulan
    # Preprocessing input
    input_tensor = preprocess_input(umur_bulan, label_gizi)

    # Predict
    pred_scores = model.predict(input_tensor)

    # Ambil top-N rekomendasi menu
    top_indices = pred_scores.argsort()[0][::-1][:3]
    recommended_menus = data_menu.iloc[top_indices]['Kombinasi Menu'].tolist()

    return recommended_menus

from imblearn.over_sampling import SMOTE
import pandas as pd
from sklearn.preprocessing import LabelEncoder

feature_columns_for_smote = [
    'child_id',
    'Umur (bulan)',
    'Tinggi Badan (cm)',
    'menu_id',
    # Add other numerical columns if needed, e.g., normalized nutrient columns
    'calories_kcal', 'fats_g', 'sod_mg', 'carb_g', 'fiber_g', 'sugar_g',
    'protein_g', 'vitA_g', 'calcium_mg', 'thiamin_mg', 'zinc_mg',
    'potassium_mg', 'magnesium_mg', 'vitE_mg', 'vitK_mcg', 'vitC_mg',
    'vitB6_mg', 'copper_mg', 'carotene_mg', 'carotene_mcg',
    'cryptoxanthin_mcg', 'lycopene_mcg', 'cholesterol_mg',
]

X = merged[feature_columns_for_smote]
y = merged['Label_Gizi']

# Terapkan SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Gabungkan kembali ke dalam DataFrame
balanced_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns),
                         pd.DataFrame(y_resampled, columns=['Label_Gizi'])], axis=1)

# Cek distribusi baru
print("Distribusi Label_Gizi setelah SMOTE:")
print(balanced_df['Label_Gizi'].value_counts())

# Penanganan Imbalance clas
from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# Konversi label ke array
labels = balanced_df['Label_Gizi'].values

# Hitung class weight
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(labels),
    y=labels
)
class_weight_dict = dict(enumerate(class_weights))
print(class_weight_dict)

import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Fitur numerik yang relevan
features = [
    'child_id',
    'Umur (bulan)', 'Tinggi Badan (cm)', 'menu_id','calories_kcal', 'fats_g', 'sod_mg', 'carb_g', 'fiber_g',
    'sugar_g', 'protein_g', 'vitA_g', 'calcium_mg', 'thiamin_mg', 'zinc_mg', 'potassium_mg',
    'magnesium_mg', 'vitE_mg', 'vitK_mcg', 'vitC_mg', 'vitB6_mg', 'copper_mg', 'carotene_mg',
    'carotene_mcg', 'cryptoxanthin_mcg', 'lycopene_mcg', 'cholesterol_mg'
]

X = balanced_df[features]
y = balanced_df['Label_Gizi']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

model = XGBClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    objective='multi:softmax',
    num_class=y.nunique(),
    eval_metric='mlogloss',
    use_label_encoder=False,
    random_state=42
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Classification Report:\n", classification_report(y_test, y_pred))
ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
plt.title("Confusion Matrix (XGBoost)")
plt.show()

def rekomendasi_makanan(child_row, menu_df, model, feature_columns, filter_by_label=False):
    umur = child_row["Umur (bulan)"]

    if umur <= 5:
        return [{
            "menu": "ASI Eksklusif ",
            "label_prediksi": "Rekomendasi utama",
            "frekuensi": "Sesuai kebutuhan bayi",
            "nutrisi": {"Keterangan": "ASI eksklusif sudah mencukupi gizi bayi <6 bulan"}
        }, {
            "menu": "Susu Formula",
            "label_prediksi": "Alternatif jika ASI tidak tersedia",
            "frekuensi": "Sesuai dosis kemasan",
            "nutrisi": {"Keterangan": "Pastikan susu formula sesuai anjuran dokter"}
        }]

    frekuensi_map = {
        "F1": "2 kali makanan utama per hari",
        "F2": "3 kali makanan utama per hari",
        "F3": "3x makanan utama + 1x snack per hari",
        "F4": "3x makanan utama + 2x snack per hari"
    }
    gizi_map = {
        0: "Sangat Pendek – Risiko tinggi stunting",
        1: "Pendek – Perlu perhatian gizi",
        2: "Normal – Pertumbuhan baik",
        3: "Tinggi – Di atas rata-rata"
    }

    rekomendasi = []
    target_label = int(child_row.get("label_gizi", 2))  # default: Normal

    for _, menu in menu_df.iterrows():
        row = {
            "child_id": child_row["child_id"],
            "Umur (bulan)": umur,
            "Tinggi Badan (cm)": child_row["Tinggi Badan (cm)"],
            "menu_id": menu["menu_id"]
        }

        # Tambahkan fitur nutrisi dari menu
        for col in feature_columns:
            if col not in row and col in menu:
                row[col] = menu[col]

        row_df = pd.DataFrame([row])[feature_columns].fillna(0)

        try:
            pred = int(model.predict(row_df).reshape(-1)[0])
        except:
            pred = -1  # jika error prediksi

        # Bisa diaktifkan/disable filter by label_gizi
        if filter_by_label and pred != target_label:
            continue

        nutrisi = {
            "kalori (kkal)": round(menu.get("calories_kcal", 0), 2),
            "protein (g)": round(menu.get("protein_g", 0), 2),
            "karbohidrat (g)": round(menu.get("carb_g", 0), 2),
            "lemak (g)": round(menu.get("fats_g", 0), 2),
            "zat besi (mg)": round(menu.get("zinc_mg", 0), 2),
            "vitamin A (g)": round(menu.get("vitA_g", 0), 2)
        }

        kode_frek = menu.get("Kode Frekuensi", "F2")
        deskripsi_frek = frekuensi_map.get(kode_frek, "Frekuensi tidak diketahui")
        deskripsi_gizi = gizi_map.get(pred, "Tidak diketahui")

        rekomendasi.append({
            "menu": menu.get("Kombinasi Menu", f"Menu {menu['menu_id']}"),
            "label_prediksi": deskripsi_gizi,
            "frekuensi": deskripsi_frek,
            "nutrisi": nutrisi
        })

    # Fallback jika kosong
    if not rekomendasi:
        fallback = menu_df.sample(5)
        for _, menu in fallback.iterrows():
            rekomendasi.append({
                "menu": menu.get("Kombinasi Menu", f"Menu {menu['menu_id']}"),
                "label_prediksi": "Alternatif (fallback)",
                "frekuensi": frekuensi_map.get(menu.get("Kode Frekuensi", "F2"), "Tidak diketahui"),
                "nutrisi": {
                    "kalori (kkal)": round(menu.get("calories_kcal", 0), 2),
                    "protein (g)": round(menu.get("protein_g", 0), 2),
                    "karbohidrat (g)": round(menu.get("carb_g", 0), 2),
                    "lemak (g)": round(menu.get("fats_g", 0), 2),
                    "zat besi (mg)": round(menu.get("zinc_mg", 0), 2),
                    "vitamin A (g)": round(menu.get("vitA_g", 0), 2)
                }
            })

    return rekomendasi[:5]

# Ambil anak tertentu dari dataset merged
# INPUTAN LANGSUNG
umur_input = 10 # contoh umur dalam bulan
tinggi_input = 85  # contoh tinggi badan dalam cm

# Buat data anak dalam format pd.Series
anak = pd.Series({
    "child_id": 999,  # dummy ID
    "Umur (bulan)": umur_input,
    "Tinggi Badan (cm)": tinggi_input,
    "label_gizi": 2
})

# Nutrisi columns dari fitur
nutrisi_cols = features[4:]

# Load data menu
menu_df = pd.read_csv("/content/data_menu_mpasi.csv")
menu_df.rename(columns={"Kode Menu": "menu_id"}, inplace=True)
menu_df['menu_id'] = pd.factorize(menu_df['menu_id'])[0].astype(int)
menu_df = menu_df[['menu_id', 'Kombinasi Menu', 'Kode Frekuensi'] + nutrisi_cols]

# --- Tambahkan prediksi status gizi anak sebelum rekomendasi menu ---
fitur_input = pd.DataFrame([{
    "child_id": anak["child_id"],
    "Umur (bulan)": anak["Umur (bulan)"],
    "Tinggi Badan (cm)": anak["Tinggi Badan (cm)"],
    "menu_id": 0  # dummy menu
}], columns=features).fillna(0)

pred_gizi = int(model.predict(fitur_input).reshape(-1)[0])

gizi_map = {
    0: "Sangat Pendek – Risiko tinggi stunting",
    1: "Pendek – Perlu perhatian gizi",
    2: "Normal – Pertumbuhan baik",
    3: "Tinggi – Di atas rata-rata"
}

print(f"\nPrediksi Status Gizi Anak : {gizi_map.get(pred_gizi, 'Tidak diketahui')}\n")

# --- Rekomendasi menu berdasarkan prediksi ---
hasil_rekomendasi = rekomendasi_makanan(anak, menu_df, model, features, filter_by_label=True)

# --- Konversi hasil ke DataFrame ---
rows = []
for item in hasil_rekomendasi:
    row = {
        "Menu": item["menu"],
        "Frekuensi": item["frekuensi"]
    }
    row.update(item["nutrisi"])
    rows.append(row)

df_hasil = pd.DataFrame(rows)

# Tampilkan semua kolom
pd.set_option('display.max_columns', None)
df_hasil

"""Berdasarkan output diatas, sistem berhasil merekomendasikan beberapa kombinasi menu teratas untuk anak tertentu dengan menggunakan model XGBoost. Model ini tidak hanya memfilter makanan berdasarkan nutrisi, tapi juga memperkirakan dampaknya terhadap status gizi. Hasil akhirnya adalah daftar makanan MPASI yang paling cocok dan bermanfaat untuk meningkatkan atau mempertahankan status gizi anak, disesuaikan dengan usia, tinggi badan, dan kombinasi makanan lainnya.

# **Pipeline Content-Based Filtering**
"""

from sklearn.metrics.pairwise import cosine_similarity

nutrient_cols = ['calories_kcal', 'fats_g', 'sod_mg', 'carb_g', 'fiber_g', 'sugar_g',
                 'protein_g', 'vitA_g', 'calcium_mg', 'thiamin_mg', 'zinc_mg',
                 'potassium_mg', 'magnesium_mg', 'vitE_mg', 'vitK_mcg', 'vitC_mg',
                 'vitB6_mg', 'copper_mg', 'carotene_mg', 'carotene_mcg',
                 'cryptoxanthin_mcg', 'lycopene_mcg', 'cholesterol_mg']

# Ambil fitur nutrisi dari menu MPASI
menu_features = food_data[nutrient_cols]

# Hitung similarity antar menu
content_sim = cosine_similarity(menu_features)

# Fungsi rekomendasi berdasarkan item (menu) yang mirip
def recommend_similar_menus(kode_menu, top_n=5):
    idx = food_data[food_data['Kode Menu'] == kode_menu].index[0]
    sim_scores = list(enumerate(content_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]
    return food_data.iloc[[i[0] for i in sim_scores]][['Kode Menu', 'Kombinasi Menu']]

# Gunakan fungsi recommend_similar_menus untuk mendapatkan rekomendasi berdasarkan kode menu
recommend_similar_menus("M122")

# Gunakan fungsi recommend_similar_menus untuk mendapatkan rekomendasi berdasarkan kode menu
recommend_similar_menus("M11")

"""Berdasarkan output diatas, sistem berhasil merekomendasikan 5 kombinasi menu teratas yang memiliki menu makanan yang paling mirip dengan kode menu 'M11'."""

# simpan model untuk format .json
import json
model.save_model("xgboost_model.json")

# simpan model untuk format .pkl (pickle)
import pickle

with open("xgboost_model.pkl", "wb") as f:
    pickle.dump(model, f)